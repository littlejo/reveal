= Contexte de la mission
:imagesdir: assets/default/images

image::mi-briefing.png[]
//mi-fallout
[NOTE.speaker]
====
Nous allons maintenant entrer dans le cÅ“ur de la mission.
====

== 511 clusters Kubernetes
:imagesdir: assets/default

video::511-clusters.mp4[opts="autoplay,loop,muted,nocontrols",role=center,width=60%]

[NOTE.speaker]
====
Je pense que tout le monde connait ici Kubernetes: l'orchestrateur de containeurs.

Notre objectif : en dÃ©ployer 511.

Combien de temps va durer ce dÃ©ploiement ?

* Pour un cluster: minimum 5 minutes
* SÃ©quentiel : 2 jours

ğŸª‚ Mais on ne fonce pas tÃªte baissÃ©e : y aller palier par palier

ğŸ› ï¸ Outils : Infrastructure As Code: automatisation | fiabilitÃ© | changement du nombre de clusters rapide
====

== Plugin CNI
:imagesdir: assets/default/images
image::cnis.png[]

[NOTE.speaker]
====
CrÃ©er les clusters, câ€™est une chose. Mais les faire communiquer entre eux, câ€™est un tout autre niveau. Pour Ã§a, on entre dans un autre domaine : la couche rÃ©seau de Kubernetes. Et câ€™est lÃ  quâ€™interviennent les plugins CNI.

Objectif :

* Donner le rÃ©seau aux cluster kubernetes
* Ã‰tablir une communication entre containers sur des serveurs distincts.

Technologies en prÃ©sence :

* ğŸ† Calico: le plus utilisÃ© historiquement
* ğŸ” Kube-router : minimaliste, BGP
* ğŸ§¬ Cilium : eBPF
====

== Kube-Proxy
image::kube-proxy.svg[]

[NOTE.speaker]
====
Les plugins CNI donnent un rÃ©seau aux pods, leur permettent de se parler.
Mais une autre question se pose : quand un pod envoie une requÃªte vers un Service Kubernetes, comment sait-on oÃ¹ diriger ce trafic ?

Ce nâ€™est pas kube-proxy qui route les paquets. Son rÃ´le, câ€™est plutÃ´t de programmer le noyau Linux Ã  lâ€™aide de iptables pour que le trafic soit redirigÃ© intelligemment.
====

== Cilium

ğŸ‘ï¸ Hubble

ğŸ” CNP & chiffrement

ğŸ§¬ Service Mesh intÃ©grÃ©

ğŸï¸ Suppression de kube-proxy

image::cilium-paint.png[width=50%]

[NOTE.speaker]
====
On a parlÃ© des principales couches rÃ©seaux de Kubernetes. Mettons maintenant en lumiÃ¨re le plugin CNI que nous allons utiliser pour cette mission.

Cilium ce n'est pas seulement un plugin CNI qui permet de donner le rÃ©seau Ã  Kubernetes, il a de nombreuses capacitÃ©s :

* ğŸ‘ï¸ ObservabilitÃ© : Hubble
* ğŸ” SÃ©curitÃ© : CNP & chiffrement
* ğŸ§¬ Service Mesh intÃ©grÃ©
* ğŸï¸ Suppression de kube-proxy

====

== Cilium Cluster Mesh
image::cilium-clustermesh.png[]

[NOTE.speaker]
====

Nous avons parlÃ© des fonctionnalitÃ©s les plus utilisÃ©s.
Mais pour cette mission en particulier, une autre fonctionnalitÃ© va jouer un rÃ´le central.
Celle qui va nous permettre de relier nos 511 clusters entre eux, comme sâ€™ils ne faisaient quâ€™un :
Cilium Cluster Mesh

ğŸš§ Conditions dâ€™activation :

* ğŸ”€ RÃ©seaux de pods disjoints
* ğŸŒ Noeuds routables entre clusters
* â›” Limite classique : 255 clusters
* ğŸ§ª NouveautÃ© 1.15 : 511 clusters possibles
====

== 2 clusters

image::2-cluster-1.png[]
[NOTE.speaker]
====

Mais avant dâ€™orchestrer 511 clusters, commenÃ§ons simple.

Regardons comment fonctionne **Cilium Cluster Mesh** avec seulement **2 clusters**.

Dans chaque cluster :

* Un **control plane** et deux **nÅ“uds workers**
* Des agents **Cilium** tournent sur chaque nÅ“ud et gÃ¨rent le rÃ©seau

Ce petit setup va nous permettre de comprendre les bases avant de passer Ã  lâ€™Ã©chelle.

Il y a deux phases pour la crÃ©ation d'un cluster mesh.
====

== Activation

image::2-cluster-2.svg[]

[NOTE.speaker]
====
Phase 1 : activation.

* pod clustermesh-api : une base de donnÃ©es etcd qui rÃ©cupÃ¨re les donnÃ©es utiles pour le cluster mesh
* svc pointe sur le pod clustermesh-api : va permetre de rÃ©cupÃ©rer les donnÃ©es de clustermesh-api

* type de svc: Nodeport | loadbalancer | clusterip

====

== !

image::2-cluster-3.svg[]

[NOTE.speaker]
====
Phase 2 : connexion

Les agents cilium rÃ©cupÃ¨re les donnÃ©es de clustermesh-api de l'autre cluster.
====

== Relier 511 clusters

:imagesdir: assets/default
video::511-clusters-connected.mp4[opts="autoplay,loop,muted,nocontrols",role=center,width=60%]

[NOTE.speaker]
====
On a vu comment relier 2 clusters.

Mais maintenant... **changement dâ€™Ã©chelle** : **511 clusters** Ã  connecter entre eux.

ğŸ“ˆ Nombre total de communications Ã  Ã©tablir :

* ğŸ§® 511Ã—510/2 = 130 305 liens
* ğŸ•’ DurÃ©e de crÃ©ation dâ€™un lien : 15 secondes
* Temps total estimÃ© : â±ï¸ 542 heures (22 jours)

* ParallÃ©lisation ?
====

== VÃ©rification de la communication

[NOTE.speaker]
====
Relier des clusters, câ€™est une chose.

Sâ€™assurer quâ€™ils **peuvent rÃ©ellement Ã©changer des paquets**, câ€™en est une autre.

Câ€™est une Ã©tape souvent nÃ©gligÃ©e.

Mais pour cette mission, **elle est incontournable**.
====

== DÃ©roulÃ© des opÃ©rations

ğŸ’° Budget serrÃ©

ğŸŒ«ï¸ Solution Cloud

[NOTE.speaker]
====
On a vu toutes les Ã©tapes techniques et les dÃ©fis Ã  venir.

Maintenant, parlons du dÃ©roulÃ© concret de la mission.

Le budget est serrÃ©, impossible dâ€™acheter 511 clusters Kubernetes.
On va donc les **louer** dans le cloud.

â³ Le challenge ? RÃ©aliser toute lâ€™opÃ©ration en **4 heures chrono**.
====

== DÃ©roulÃ© de chaque opÃ©ration

ğŸš€ Provisionner les 511 clusters

ğŸ”— Connecter chacun Ã  tous les autres

ğŸ§ª Tester la communication

ğŸ’£ DÃ©truire proprement

ğŸ§¼ VÃ©rifier que rien nâ€™a survÃ©cu

[NOTE.speaker]
====
Comment va se dÃ©rouler chaque Ã©tape ?

* Provisionner un grand nombre de clusters
* Les connecter entre eux
* Tester que la communication fonctionne
* Tout dÃ©truire proprement
* Et vÃ©rifier quâ€™aucune ressource nâ€™a Ã©tÃ© oubliÃ©e
====
